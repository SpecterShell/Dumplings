Version: 0.3.32
Installer: []
Locale:
- Locale: en-US
  Key: ReleaseNotes
  Value: |-
    0.3.32 - Release Notes
    Build 2
    - Support for GLM 4.5 tool calling
    - [MLX] Fixed prompt template bug that caused GLM-4.1V to not recognize images
    - Support for olmOCR-2
    - Fix a bug where sometimes Download button would continue showing for an already downloaded model
    Build 1
    - Support for passing base64 images into OpenAI-compatible /v1/responses endpoint
      - See https://platform.openai.com/docs/guides/images-vision?api-mode=responses&format=base64-encoded#giving-a-model-images-as-input for details
    - Flash Attention is now enabled by default for Vulkan and Metal llama.cpp engines
    - Fix OpenAI-compatible /v1/responses endpoint "previous_response_not_found" bug due to internal file read error
    - Fix a bug where update toast would sometimes retrigger and close
    - Fix the "No model selected for this chat and no lastUsedModel recorded. Please select a model" error
    - Fixed cases where downloading additional variants of the same model sometime wouldn't get nested correctly
