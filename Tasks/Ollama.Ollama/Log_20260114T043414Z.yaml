Version: 0.14.0
Installer:
- InstallerType: inno
  InstallerUrl: https://github.com/ollama/ollama/releases/download/v0.14.0/OllamaSetup.exe
Locale:
- Locale: en-US
  Key: ReleaseNotes
  Value: |-
    What's Changed
    - ollama run --experimental CLI will now open a new Ollama CLI that includes an agent loop and the bash tool
    - Anthropic API compatibility: support for the /v1/messages API
    - A new REQUIRES command for the Modelfile allows declaring which version of Ollama is required for the model
    - For older models, Ollama will avoid an integer underflow on low VRAM systems during memory estimation
    - More accurate VRAM measurements for AMD iGPUs
    - Ollama's app will now highlight swift soure code
    - An error will now return when embeddings return NaN or -Inf
    - Ollama's Linux install bundles files now use zst compression
    - New experimental support for image generation models, powered by MLX
    New Contributors
    - @Vallabh-1504 made their first contribution in https://github.com/ollama/ollama/pull/13550
    - @majiayu000 made their first contribution in https://github.com/ollama/ollama/pull/13596
    - @harrykiselev made their first contribution in https://github.com/ollama/ollama/pull/13615
    Full Changelog: https://github.com/ollama/ollama/compare/v0.13.5...v0.14.0-rc2
- Key: ReleaseNotesUrl
  Value: https://github.com/ollama/ollama/releases/tag/v0.14.0
ReleaseTime: 2026-01-10T08:33:45.0000000Z
